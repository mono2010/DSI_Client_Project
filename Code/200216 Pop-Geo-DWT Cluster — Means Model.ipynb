{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install  rasterio\n",
    "import numpy as np\n",
    "import pywt\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import itertools as it\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 900_000_000\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import zipfile \n",
    "import urllib.request\n",
    "import random\n",
    "import functools as fct\n",
    "import math as mt\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "from skimage.color import rgb2gray\n",
    "import pywt\n",
    "import datetime\n",
    "import io\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a function to convert lat, long into pixel location. The \n",
    "# `transform` method gives us the affine relationship with which to \n",
    "# accomplish this.  The transform however is from pixel indices\n",
    "# to spatial coordinates. We require the opposite.\n",
    "#\n",
    "# Specifically, the location 𝗹 = 𝗔 𝗽 + 𝗯, where 𝗽 are the pixel\n",
    "# coordinates, 𝗔 is the coefficient matrix of the affine transform,\n",
    "# and 𝗯 is the intercept.  We want pixel location 𝗽 = (𝗹 - 𝗯)𝗔⁻¹.  \n",
    "# We calculate this for individual pixels and for groups.\n",
    "\n",
    "# Convert the transform object into coefficient matrix 𝗔 and\n",
    "# intercept vector 𝗯. \n",
    "def λ_pixel(λ_coord, affine_xform):\n",
    "    𝗔 = np.reshape(a = np.array(affine_xform[:6]),\n",
    "                   newshape = (2,3))[:,:2]\n",
    "    𝗯 = np.expand_dims(a = np.reshape(a = np.array(affine_xform[:6]),\n",
    "                                      newshape = (2,3))[:,-1],\n",
    "                       axis = -1)\n",
    "    #\n",
    "    # Calculate and return the pixel location.\n",
    "    return int((λ_coord - 𝗯.item(1)) * np.linalg.inv(𝗔).item(1,1))\n",
    "def 𝘓_pixel(𝘓_coord, affine_xform):\n",
    "    𝗔 = np.reshape(a = np.array(affine_xform[:6]),\n",
    "                   newshape = (2,3))[:,:2]\n",
    "    𝗯 = np.expand_dims(a = np.reshape(a = np.array(affine_xform[:6]),\n",
    "                                      newshape = (2,3))[:,-1],\n",
    "                       axis = -1)\n",
    "    #\n",
    "    # Calculate and return the pixel location.\n",
    "    return int((𝘓_coord - 𝗯.item(0)) * np.linalg.inv(𝗔).item(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACQUIRE COUNTRY-WIDE POPULATION-DENSITY MAP. \n",
    "# Our procedure comes from StackOverflow:\n",
    "#         https://discuss.analyticsvidhya.com/t/how-to-read-zip-file-directly-in-python/1659\n",
    "# \n",
    "urllib.request.urlretrieve('https://data.humdata.org/dataset/cbfc4206-35c8-42d4-a096-b2dd0aec983d/resource/1b7e9361-651a-4bf2-839b-eaf5c5f45ec1/download/population_zaf_2018-10-01.csv.zip',\n",
    "                           'sa_pop.zip')\n",
    "sa_pop_zip = zipfile.ZipFile('sa_pop.zip')\n",
    "sa_pop_csv = pd.read_csv(filepath_or_buffer = sa_pop_zip.open('population_zaf_2018-10-01.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in image layer — a bitmap image exported from Google Maps and georeferenced in QGIS.\n",
    "dataset = rasterio.open('./200216 J-Berg O-head Image_modified.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate imagery resolution.  One degree of longitidue is approximately\n",
    "# 111.32 km. From our dataset.bounds attribute we get the bounding\n",
    "# latitudes. The dataset.height attribute gives us the vertical\n",
    "# pixel count.\n",
    "image_res = (dataset.bounds.top - dataset.bounds.bottom)*111.32*1000/dataset.height\n",
    "print(f'Approximate image resolution: {round(image_res, 1)} meters per pixel.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window country-wide data to our rectangular Johannesberg region window. \n",
    "jberg_pop = sa_pop_csv.loc[ (sa_pop_csv['Lat'].between(left = dataset.bounds.bottom,\n",
    "                                                       right = dataset.bounds.top)) &\\\n",
    "                            (sa_pop_csv['Lon'].between(left = dataset.bounds.left,\n",
    "                                                         right = dataset.bounds.right))]\n",
    "jberg_pop.head(n = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the georeferenced population-estimates to pixel coordinates so \n",
    "# that we can scatter-plot them into the image.\n",
    "𝗔 = np.reshape(a = np.array(dataset.transform[:6]),\n",
    "               newshape = (2,3))[:,:2]\n",
    "𝗯 = np.expand_dims(a = np.reshape(a = np.array(dataset.transform[:6]),\n",
    "                                  newshape = (2,3))[:,-1],\n",
    "                   axis = -1)\n",
    "jberg_pop_pix_raster = pd.DataFrame(data = np.dot(b = np.ndarray.transpose(jberg_pop[['Lon', 'Lat']].to_numpy() - np.transpose(𝗯)),\n",
    "                                                   a = np.linalg.inv(𝗔)),\n",
    "                                     index = ['Longitude, L', 'Latitude, λ'],\n",
    "                                     columns = jberg_pop.index).T\\\n",
    "                                                               .astype(int)#\\\n",
    "#                                                                .assign(λ = lambda Ξ : dataset.height - Ξ['Latitude, λ'])\\\n",
    "#                                                                .drop(labels = 'Latitude, λ',\n",
    "#                                                                      axis = 1)\\\n",
    "#                                                                .rename(columns = {'λ' : 'Latitude, λ'})\n",
    "jberg_pop_pix_raster.head(n = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify frame ticks and labels for our image plot.  The matplotlib.pyplot.imshow\n",
    "# defaults to pixels in each dimension. We want to look at things in terms\n",
    "# of (λ, 𝘓).\n",
    "𝘓_ticks_labels = [round(tick_lab, 4)\n",
    "                      for tick_lab in np.arange(start = 27.95,\n",
    "                                               stop = 28.17,\n",
    "                                               step = 0.01)]\n",
    "𝜆_ticks_labels = [round(tick_lab, 4)\n",
    "                    for tick_lab in np.arange(start = -26.06,\n",
    "                                               stop = -26.20,\n",
    "                                               step = -0.01)]\n",
    "𝘓_ticks = [𝘓_pixel(tick_tab, dataset.transform)\n",
    "                for tick_tab in 𝘓_ticks_labels]\n",
    "𝜆_ticks = [dataset.height - 𝜆_pixel(tick_tab, dataset.transform)\n",
    "                for tick_tab in 𝜆_ticks_labels]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo-window our data so that we only process the population measurements\n",
    "# within an area not marked by our Google-maps pins used to georeference\n",
    "# the image we got from it.\n",
    "process_window = {'λ' : {'South' : -26.152,\n",
    "                        'North' : -26.07125},\n",
    "                 '𝘓' : {'West' : 27.96,\n",
    "                        'East' : 28.135}}\n",
    "processing_box_geo = np.array([[process_window.get('𝘓').get('West'), process_window.get('𝘓').get('East'),\n",
    "                                process_window.get('𝘓').get('East'), process_window.get('𝘓').get('West'),\n",
    "                                process_window.get('𝘓').get('West')],\n",
    "                               [process_window.get('λ').get('South'), process_window.get('λ').get('South'),\n",
    "                                process_window.get('λ').get('North'), process_window.get('λ').get('North'),\n",
    "                                process_window.get('λ').get('South')]])\n",
    "processing_box_pixel = np.dot(b = processing_box_geo - 𝗯,\n",
    "                              a = np.linalg.inv(𝗔)).astype(int)\n",
    "processing_box_pixel[1,:] = dataset.height - processing_box_pixel[1,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window Johannesberg data to our processing box. Then convert (λ, 𝘓) to\n",
    "# pixel indices.\n",
    "jberg_proc_window = jberg_pop.loc[jberg_pop['Lat'].between(right = process_window.get('λ').get('North'),\n",
    "                                                           left = process_window.get('λ').get('South')) &\\\n",
    "                                  jberg_pop['Lon'].between(left = process_window.get('𝘓').get('West'),\n",
    "                                                           right = process_window.get('𝘓').get('East'))]\n",
    "jberg_proc_raster = pd.DataFrame(data = np.dot(b = jberg_proc_window[['Lon', 'Lat']]\\\n",
    "                                                                     .T\\\n",
    "                                                                     .to_numpy() - 𝗯,\n",
    "                                               a = np.linalg.inv(𝗔)).astype(int),\n",
    "                                 index = ['pix_Lon', 'pix_Lat'],\n",
    "                                 columns = jberg_proc_window.index).T\n",
    "jberg_proc_raster.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (22,10))\n",
    "plt.imshow(np.stack([dataset.read(im_layer)\n",
    "                      for im_layer in dataset.indexes],\n",
    "                     axis = -1))\n",
    "plt.xticks(ticks = 𝘓_ticks,\n",
    "           labels = 𝘓_ticks_labels);\n",
    "plt.yticks(ticks = 𝜆_ticks,\n",
    "           labels = 𝜆_ticks_labels);\n",
    "plt.xlim(left = 0, \n",
    "         right = dataset.width),\n",
    "plt.ylim(bottom = 0,\n",
    "         top = dataset.height);\n",
    "plt.xlabel(xlabel = 'Longitude, L',\n",
    "           fontsize = 18)\n",
    "plt.ylabel(ylabel = 'Latitude, λ',\n",
    "           fontsize = 18);\n",
    "plt.scatter(jberg_pop_pix_raster['Longitude, L'],\n",
    "            jberg_pop_pix_raster['Latitude, λ'],\n",
    "            s = 2,\n",
    "            color = '#ff304225');\n",
    "plt.scatter(jberg_proc_raster['pix_Lon'],\n",
    "            jberg_proc_raster['pix_Lat'],\n",
    "            s = 1,\n",
    "            color = '#f2a90075');\n",
    "plt.title(label = 'Facebook population measurement overlaid \\n onto overhead image of target area',\n",
    "          fontsize = 28,\n",
    "          color = '#003459');\n",
    "plt.plot(processing_box_pixel[0,:],\n",
    "         processing_box_pixel[1,:],\n",
    "         color = '#73cbf2');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract our RGB image out of the rasterio object and convert it to \n",
    "# a gray-scale array.  We do this in two steps.  We first use\n",
    "# list comperemension to extract each band. We then use the scikit-image\n",
    "# rgb-to-gray scale to combine the color channels. \n",
    "jberg_img_array = rgb2gray(np.stack([dataset.read(band_idx)\n",
    "                                              for band_idx in dataset.indexes],\n",
    "                                         axis = -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a model-data matrix for which the explanatory variables include the\n",
    "# lat and long (λ, 𝘓), the population, measurements, and discrete wavelet-transform\n",
    "# coefficients from a 128×128-pixel window centered on the population-density\n",
    "# measurement. Once scaled, this will be the data for a k-means clustering\n",
    "# analysis of the data. \n",
    "#\n",
    "# We operate on our jberg_proc_raster dataframe, in which we identified\n",
    "# all of the measurements within our processing \"box\" and identified\n",
    "# their pixel indices.  These indices form the center of our 128×128-pixel\n",
    "# windows for DWT analysis.\n",
    "#\n",
    "# ⓵ Initialize a dictionary in which to collect the data.\n",
    "pop_geo_dwt_dict = dict()\n",
    "\n",
    "# ⓶ Now, cycle through all of the indices for our jberg_proc_raster data frame\n",
    "#   whose columns contain pixel-indices for each population-density measurement.\n",
    "for pop_meas in jberg_proc_raster.index:\n",
    "    # ⓐ Extract from our image array the 128×128-pixel window.  The image array\n",
    "    #    is gray-scale, so our windows are two-dimensional.\n",
    "    dwt_window = jberg_img_array[(jberg_proc_raster.loc[pop_meas, 'pix_Lat'] - 64):(jberg_proc_raster.loc[pop_meas, 'pix_Lat'] + 64),\n",
    "                                 (jberg_proc_raster.loc[pop_meas, 'pix_Lon'] - 64):(jberg_proc_raster.loc[pop_meas, 'pix_Lon'] + 64)]\n",
    "    #\n",
    "    # ⓑ Calculate a three-level DWT on each window.  Use the length-four Daubechies wavelet\n",
    "    #    filter.  It is strictly real, and it provides perfect-reconstruction.\n",
    "    dwt_xform = pywt.wavedec2(data = dwt_window,\n",
    "                              wavelet = 'db3',\n",
    "                              level = 3)\n",
    "    #\n",
    "    # ⓒ Collect all of our explanatory variables a one-dimensional numpy array.\n",
    "    #    For each population-density measurement, we append together three\n",
    "    #    sources:\n",
    "    #     ⅰ. The lat, long, and population-density measurement from our ouriginal data\n",
    "    #        matrix;\n",
    "    #     ⅱ. The zeroth array returned by the dwt, which represents the final approximation; and\n",
    "    #     ⅲ. All of the detail arrays. \n",
    "    #    We end up with a dictionary for which the keys are the indices from the\n",
    "    #    population-density measurements in our processing box, and the values are\n",
    "    #    the above-described variables.  We use in-place dictionary.update method\n",
    "    #    to append each new (key, val) pair to the dictionary as we calculate.\n",
    "    #\n",
    "    #    Since we have to concatenate more than two arrays via the numpy.append,\n",
    "    #    we use the functools.reduce applied to a lambda operator.\n",
    "    pop_geo_dwt_dict.update({pop_meas : fct.reduce(lambda Ξ, Ζ : np.append(Ξ, Ζ),\n",
    "                                                                 [jberg_pop.loc[pop_meas].to_numpy(),\n",
    "                                                                  np.ndarray.flatten(dwt_xform[0]),\n",
    "                                                                  np.ndarray.flatten(np.stack(arrays = dwt_xform[1],\n",
    "                                                                             axis = -1))])})\n",
    "#\n",
    "# ⓷ Transform all of our information into a data frame.\n",
    "pop_geo_dwt_df = pd.DataFrame.from_dict(data = pop_geo_dwt_dict,\n",
    "                                        orient = 'index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pop_geo_dwt_df.head(n = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data with sklearn.preprocessing.StandardScaler()\n",
    "pop_geo_dwt_scaler = StandardScaler()\n",
    "pop_geo_dwt_scaler.fit(X = pop_geo_dwt_df)\n",
    "pop_geo_dwt_scaled = pop_geo_dwt_scaler.transform(X = pop_geo_dwt_df)\n",
    "#\n",
    "# Perform singular-value decomposition (PCA).  It turns out that\n",
    "# a relative small number of dimensions explain most of the variance.\n",
    "(𝗨, 𝝨, 𝗩ᵀ) = np.linalg.svd(a = pop_geo_dwt_scaled,\n",
    "                           full_matrices = False,\n",
    "                           compute_uv = True)\n",
    "pop_geo_dwt_pca = PCA()\n",
    "pop_geo_dwt_pca.fit(pop_geo_dwt_scaled)\n",
    "pop_geo_dwt_princ_comps = pop_geo_dwt_pca.transform(pop_geo_dwt_df)[:, \n",
    "                                                                        :np.sum(np.cumsum(np.square(𝝨))/np.sum(np.square(𝝨)) <= 0.95)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} of {} components account for 95% of variance'\\\n",
    "      .format((np.sum(np.cumsum(np.square(𝝨))/np.sum(np.square(𝝨)) <= 0.95)),\n",
    "               pop_geo_dwt_princ_comps.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCAN KMEANS n_clusters hyper prameters.\n",
    "pop_geo_dwt_kmeans_fit = dict()\n",
    "print('Starting at {}'.format(datetime.datetime.utcnow().strftime('%y-%m-%d, %H%M%SZ')))\n",
    "n_clust = 5;\n",
    "for n_clust in np.arange(start = 15,\n",
    "                          stop = 50,\n",
    "                          step = 5):\n",
    "    print('Time: {};  Started {}-cluster KMeans fit'.format(datetime.datetime.utcnow().strftime('%H%M%SZ'),\n",
    "                                                  n_clust))\n",
    "    pop_geo_dwt_kmeans = KMeans(n_clusters = n_clust,\n",
    "                                random_state = 30214,\n",
    "                                n_jobs = -1,\n",
    "                                verbose = 1)\n",
    "    pop_geo_dwt_kmeans.fit(pop_geo_dwt_scaled)\n",
    "    score = silhouette_score(pop_geo_dwt_scaled,\n",
    "                             pop_geo_dwt_kmeans.labels_)\n",
    "    pop_geo_dwt_kmeans_fit.update({str(n_clust) : {'labels' : list(map(str, pop_geo_dwt_kmeans.labels_)),\n",
    "                                                  'score' : score}})\n",
    "    print('Time: {};  Finished {}-cluster KMeans fit'.format(datetime.datetime.utcnow().strftime('%H%M%SZ'),\n",
    "                                                              n_clust))\n",
    "    with io.open('./pop_geo_dwt_kmeans_fit_lvl3_win128_unscaled.json', 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(pop_geo_dwt_kmeans_fit, \n",
    "                  f, \n",
    "                  ensure_ascii = False, \n",
    "                  indent = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
